{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "0044652d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw9.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d00680e",
   "metadata": {},
   "source": [
    "# Homework 9: Predictive Modelling and Model Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c35cf4",
   "metadata": {},
   "source": [
    "Name: Colin Jette and Ritika Tejwani\n",
    "\n",
    "Student ID: 498446 and 498283\n",
    "\n",
    "Collaborators: NA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fad084",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "This is the final homework/Project, which is about Understanding Data Profiling, Feature Engineering, Feature Selection, Model Comparision & Selection as a _final project_ for our 217a class.\n",
    "\n",
    "We will be using the techniques and approaches introduced throughout the course focusing mainly towards the second half of the semester:\n",
    "\n",
    "* [M0] Python for DS\n",
    "* [M1] The DS and ML Workflows\n",
    "* [M2] Exploratory Data Analsyis\n",
    "* **[M3] Linear Regression (if applicable - depends on problem/dataset)**\n",
    "* **[M4] Linear Classification (if applicable - depends on problem/dataset)**\n",
    "* [M5] Sentiment Analysis (if applicable - depends on problem/dataset)\n",
    "* [M6] Learning Principles and Ethical Thinking for DS\n",
    "* **[M7] Clustering K-Means (if applicable - depends on problem/dataset)** \n",
    "* **[M8] Similarity-based Learning K-NN (if applicable - depends on problem/dataset)**\n",
    "* **[M9] More Models (Decision Tree, Random Forest, Neural Network) for Feature Engineering & Model Comparision & Selection**\n",
    "* **[M10] Creating & Managing Model pipeline for ML workflow**\n",
    "\n",
    "The main focus of this project is majorly on the last modules [M3]-[M10]. In particular, it will be helpful to review **Lab 3 & hw 3 onwards for more clarification**.\n",
    "Most of the things you will do in this final project are explained in `Lab9` and `Lab 10`. Then, review the other labs and hws to recap the general workflow of our DS approaches to the various problems we have worked on so far. This will help you to be prepared for all the steps in this project, so that you do not miss anything. \n",
    "\n",
    "In gernal, you should feel free to import any package that we have previously used in class. Ensure that all plots have the necessary components that a plot should have (e.g. axes labels, a title, a legend).\n",
    "\n",
    "Additionally, note that this assignment is more like a project than a typical homework and it will have a slightly different structure than the hws in the past. One of the reasons why Jupyter Notebooks are so popular in the field is because you can really treat them like notebooks to explain your findings as you discover them. In this assignment, we provide some **Problem** stubs following the DS workflow and you will need to fill in the analysis and structure as you go.\n",
    "\n",
    "Furthermore, in addition to recording your collaborators on this homework, please also remember to cite/indicate all external sources used when finishing this assignment. This includes peers, TAs, and links to online sources. \n",
    "\n",
    "Frequently **save** your notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fa7925",
   "metadata": {},
   "source": [
    "### Collaborators and Sources\n",
    "Furthermore, in addition to recording your **collaborators** on this homework, please also remember to **cite/indicate all external sources** used when finishing this assignment. \n",
    "> This includes peers, TAs, and links to online sources. \n",
    "\n",
    "Note that these citations will not free you from your obligation to submit your _own_ code and write-ups, however, they will be taken into account during the grading and regrading process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2b483dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collaborators and sources:\n",
    "# Albert Einstein and Marie Curie\n",
    "# https://developers.google.com/edu/python/strings\n",
    "\n",
    "# your code here\n",
    "answer = 'my answer'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37be1bf3",
   "metadata": {},
   "source": [
    "### Submission instructions\n",
    "* Submit this Python notebook, including your answers in the code cells as homework submission.\n",
    "* **Feel free to add as many cells as you need to** â€” just make sure you don't change what we gave you. \n",
    "* **Does it spark joy?** Note that you will be partially graded on the presentation (_cleanliness, clarity, comments_) of your notebook so make sure you [Marie Kondo](https://lifehacker.com/marie-kondo-is-not-a-verb-1833373654) your notebook before submitting it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a1d6a5",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "For our final project this semester, we'll take a look at data for California Housing Price Prediction\n",
    "https://www.kaggle.com/subashdump/california-housing-price-prediction/data \n",
    "\n",
    "\n",
    "As you have seen throughout the semseter we have learned various techniques to solve a problem task (Classification, Regression, Clustering etc.) starting from problem formulation to EDA to model building to model evaluation and performing feaure engineering and selection in order to improve the model's performance.\n",
    "You will be combining all the knowledge learned so far in this final project. You will be making assuptions and decisions on your own with appropriate justifications in writeups about how to improve the prediction model using all the tools and techniques learned so far and provide the best model at the end.\n",
    "\n",
    "\n",
    "The project aims at building a model of housing prices to predict median house values in California using the provided dataset. This model should learn from the data and be able to predict the median housing price in any district, given all the other metrics.\n",
    "\n",
    "Our goal will be to use this dataset to gain some insight about characteristics of different features.\n",
    "We will be using data profiling from pandas and create models (hopefully more than 3) and complare them to find out which model performed the best and probably explain why it is the best model among all in this data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f8a5feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc4354f",
   "metadata": {},
   "source": [
    "### Problem 1.1\n",
    "\n",
    "Download the data and load it in this notebook for further processing and analysis.\n",
    "\n",
    "**Write-up!** Describe the data, answering questions including, but not limited to, these: Where does the data come from? How was it obtained? How many examples and features does the dataset have? What kinds of features are in the dataset? What values can these features take? what kind of relationship you would explore in this dataset and on what features? \n",
    "> **Hint**: Consider the steps of EDA; what would you like to know about this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "074cfa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "data = pd.read_csv(\"utility/data/housing.csv\")\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "fb2a2718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 10)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e7c1a38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'median_house_value', 'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "97598993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2f8203b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a4108fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.569704</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003532</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
       "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
       "std        2.003532      2.135952           12.585558   2181.615252   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
       "mean       537.870553   1425.476744    499.539680       3.870671   \n",
       "std        421.385070   1132.462122    382.329753       1.899822   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        296.000000    787.000000    280.000000       2.563400   \n",
       "50%        435.000000   1166.000000    409.000000       3.534800   \n",
       "75%        647.000000   1725.000000    605.000000       4.743250   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        20640.000000  \n",
       "mean        206855.816909  \n",
       "std         115395.615874  \n",
       "min          14999.000000  \n",
       "25%         119600.000000  \n",
       "50%         179700.000000  \n",
       "75%         264725.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0dd39",
   "metadata": {},
   "source": [
    "**Problem 1.1:** <br>\n",
    "The data comes from the Kaggle which is a data science company that contains data sets on a variety of topics. This specific data is about houses in a given California district, and gives the summary stats about them based on the 1990 census data. This data set has 20640 data points and 10 features per data point. The features in the data set are longitude, latitude, housing median age, total rooms, total bedrooms, population, households, median income, median house value, and ocean proximity. All the features beside ocean_proximity are continuous numerical variables. Ocean_proximity is a categorical variable because it's represented by a string. Since this data set is about predicting house prices, I would want to explore what features have the most correlation with the median house value, and what features have the most accuracy in predicting house prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db225c",
   "metadata": {},
   "source": [
    "### Problem 1.2\n",
    "### Getting Familiar with the Data\n",
    "\n",
    "Install the pandas data profile dependencies and import them to generate the data report using __df.profile_report__. \n",
    "\n",
    "\n",
    "**Write-up!** What is the Domain/Area of this dataset and what kind of prediction (regression, classification or clustering) we are doing with this dataset and why? Describe the additional insights (if any) you get from generating the pandas data profile report, which you did not observe in the previous EDA steps. Does it change your thinking process or provide any ideas about data pre-processing or processing steps? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "1e3a10c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-profiling==3.5.0 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (3.5.0)\n",
      "Requirement already satisfied: statsmodels<0.14,>=0.13.2 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (0.13.5)\n",
      "Requirement already satisfied: visions[type_image_path]==0.7.5 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (0.7.5)\n",
      "Requirement already satisfied: multimethod<1.10,>=1.4 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (1.9)\n",
      "Requirement already satisfied: typeguard<2.14,>=2.13.2 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (2.13.3)\n",
      "Requirement already satisfied: numpy<1.24,>=1.16.0 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (1.19.2)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (6.0)\n",
      "Requirement already satisfied: matplotlib<3.7,>=3.2 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (3.3.2)\n",
      "Requirement already satisfied: requests<2.29,>=2.24.0 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: tqdm<4.65,>=4.48.2 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (4.64.0)\n",
      "Requirement already satisfied: seaborn<0.13,>=0.10.1 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (0.11.1)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (0.12.2)\n",
      "Requirement already satisfied: pydantic<1.11,>=1.8.1 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (1.10.0)\n",
      "Requirement already satisfied: pandas!=1.4.0,<1.6,>1.1 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (1.2.0)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (3.0.3)\n",
      "Requirement already satisfied: scipy<1.10,>=1.4.1 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (1.5.2)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas-profiling==3.5.0) (0.1.12)\n",
      "Requirement already satisfied: networkx>=2.4 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling==3.5.0) (2.6.3)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling==3.5.0) (21.4.0)\n",
      "Requirement already satisfied: tangled-up-in-unicode>=0.0.4 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling==3.5.0) (0.2.0)\n",
      "Requirement already satisfied: imagehash in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling==3.5.0) (4.3.1)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from visions[type_image_path]==0.7.5->pandas-profiling==3.5.0) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from jinja2<3.2,>=2.11.1->pandas-profiling==3.5.0) (2.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->pandas-profiling==3.5.0) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->pandas-profiling==3.5.0) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->pandas-profiling==3.5.0) (2022.6.15)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->pandas-profiling==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from matplotlib<3.7,>=3.2->pandas-profiling==3.5.0) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pandas!=1.4.0,<1.6,>1.1->pandas-profiling==3.5.0) (2022.1)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from phik<0.13,>=0.11.1->pandas-profiling==3.5.0) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from pydantic<1.11,>=1.8.1->pandas-profiling==3.5.0) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->pandas-profiling==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->pandas-profiling==3.5.0) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from requests<2.29,>=2.24.0->pandas-profiling==3.5.0) (3.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from statsmodels<0.14,>=0.13.2->pandas-profiling==3.5.0) (21.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from statsmodels<0.14,>=0.13.2->pandas-profiling==3.5.0) (0.5.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from patsy>=0.5.2->statsmodels<0.14,>=0.13.2->pandas-profiling==3.5.0) (1.16.0)\n",
      "Requirement already satisfied: PyWavelets in /opt/anaconda3/envs/cse217a/lib/python3.7/site-packages (from imagehash->visions[type_image_path]==0.7.5->pandas-profiling==3.5.0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# BEGIN SOLUTION\n",
    "!pip install pandas-profiling==3.5.0\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f5d9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb66d4d3f35483a83706c4e23bbf92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "ProfileReport(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cfdefa",
   "metadata": {},
   "source": [
    "**Problem 1.2** <br>\n",
    "The domain of this dataset is housing prices in different California districts. We want to make regressional predictions with this data set because we're dealing with mostly numerical values, and we want to predict another numerical value by fitting a model with the necessary data to train in. From the profile report, it says that there are a total 207 missing cells, all from the total_bedrooms feature. This is important because since there are missing cells, we must clean the data to get rid of the missing cells so it doesn't skew the regressional model. From the ocean_proximity, I see that the column has 5 distinct values, so maybe there's a way to numerically categorize those 5 distinct values so I can numerically analyze them. We can also see from the profile report that median income has the highest correlation with house value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bc3a39",
   "metadata": {},
   "source": [
    "### Problem 1.3: Data Description and Pre-processing\n",
    "\n",
    "**Write-up!** What are the major highlights and interesting points in the report generated in the previous cell (or your own EDA process). \n",
    "Describe your insights and thought process regarding those insightful aspects of the data/features/graph/statistics in terms of general relationship among features such as correlation, interaction, cardinality, distribution, missing data, outliers etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ed78c1",
   "metadata": {},
   "source": [
    "**Problem 1.3** <br>\n",
    "From the correlation matrix, I can see that median house value is highly correlated to median income, so I might want to explore how accurate the income is in predicting the house value. Additionally, from before, the ocean_proximit has 5 distinct values, so maybe there's some way to incorporate the ocean_size data into the regressional mdoel to see if the house value has any correlation with its nearest distance to an ocean. Based solely on outliers, from the pandas profile report, I can see that house median age and median house value have outliers, which might skew the regressional model accuracy. All of the 207 missing values are from the total_bedrooms column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53287d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(\"<1H OCEAN\", 1).replace(\"INLAND\", 2).replace(\"NEAR OCEAN\", 3).replace(\"NEAR BAY\", 4).replace(\"ISLAND\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e8d1db",
   "metadata": {},
   "source": [
    "To initially pre-process the data, we want to convert the categorical variable ocean_proximity to a numerical variable, which is what the code above does. The updated column is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84bc0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ocean_proximity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6b5d01",
   "metadata": {},
   "source": [
    "### Problem 1.4: Split the Data (you will be using the same data split (train-validation-test) for all the models in the following questions )\n",
    "\n",
    "Extract input (X) and output (y) data from the dataset. \n",
    "\n",
    "Use the train and test split and k-fold cross validation (use 5 fold cross validation) from the scikit learn library to split the data into 80% training and 20% testing.\n",
    "\n",
    "**NOTE** Remember that you will be using the same cross validation and train test splits values for all the predictive modeling part (Problem 3) for the fair comparision at the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb547016",
   "metadata": {},
   "source": [
    "**Write-up!** Why 80% train and 20% test split is considered a good practice? How would you pick the train-test split size if the dataset is relatively small or large? What is the purpose of using cross validation technique and how does it ensure model robustness? What is Data snooping and how do you avaoid it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c7e5c",
   "metadata": {},
   "source": [
    "**Problem 1.4:** <br>\n",
    "Studies show that the most accurate results are obtained if we use 20% of the data for testing and the remaining 80% of the data for training. Also, according to the 80/20 rule of model validation, 80% of the outcomes come from 20% of the causes, so using 20% of the factors will produce the best results. \n",
    "If the dataset is relatively small, we would want to increase the amount of testing data and make the train-test split 70/30. However for large datasets, we have an abundance of testing data with 20% of the data, so we would want to significantly decrease this to almost a 99/1 ratio. \n",
    "The purpose of cross validation is to estimate the performance of a specific model on untrained data by using a limited sample validation data. \n",
    "Cross validation ensures model robustness because it minimizes underfitting and overfitting so that the model's performance won't significantly change when using tseting data vs training data.\n",
    "Data snooping is the insertion of bias/misuse in data statistical analysis to artificially prove statistically significant results that may be highly inaccurate.\n",
    "To avoid data snooping, you want to use all the data and not remove important features to minimize bias from the data in order to get statistically significant results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef02b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "data_new = data.drop_duplicates()\n",
    "data_new = data.dropna()\n",
    "\n",
    "X = np.float64(data_new.copy().drop(['median_house_value', 'ocean_proximity'], axis=1))\n",
    "y = np.float64(data_new.copy().drop(['latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'median_income', \n",
    "           'ocean_proximity'], axis=1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = None)\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(\"Fold\", fold, \":\")\n",
    "    print(\"Train index: \", train_index)\n",
    "    print(\"Test index: \", test_index)\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2661ba0",
   "metadata": {},
   "source": [
    "### Problem 1.5: Perform Linear Regression\n",
    "\n",
    "Let's create a baseline model here:\n",
    "\n",
    "Perform Linear Regression on training data. Predict the output for the test dataset using the fitted model. Print the root mean squared error (RMSE) and R^2 value from Linear Regression for test data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06482f67",
   "metadata": {},
   "source": [
    "**Write-up!** Why do we use R^2 values when we have other error measures (MAE, MSE, RMSE etc.)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f23dad",
   "metadata": {},
   "source": [
    "**Problem 1.5:** <br>\n",
    "We use R^2 values because they tell us how well the predictor variables can explain the variation in the response variable. Additionally, we use R^2 values because R^2 values are standardized, and therefore we're able to easily compare the accuracy of models since R^2 values aren't differentiated by the scalar effects of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "r_squared_array = np.zeros(5)\n",
    "rmse_array = np.zeros(5)\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle=True, random_state = None)\n",
    "    \n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "    X_train = X[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    y_train = y[train_idx]\n",
    "    y_test = y[test_idx]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model = model.fit(X_train,y_train)\n",
    "    r_squared = model.score(X_test,y_test)\n",
    "    r_squared_array[fold] = r_squared\n",
    "    \n",
    "    mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "    rmse = np.sqrt(mse)\n",
    "    rmse_array[fold] = rmse\n",
    "    \n",
    "    \n",
    "print(\"R-squared:\", np.mean(r_squared_array))\n",
    "print(\"RMSE:\", np.mean(rmse_array))\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492236b2",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1103278",
   "metadata": {},
   "source": [
    "### Problem 2.1 \n",
    "\n",
    "Identify features which needs feature engineering after looking at the baseline model's result. Perform Feature Tranformation/Manipulation/Engineering in this step and use this knowledge in predictive modeling part. \n",
    "\n",
    "Apply some feature generation technices in order to make those features more useful for the data such as checking the datatypes, handling missing values, extracting new features from existing ones, encoding some features if categorical, scaling, standardization etc. \n",
    "\n",
    "**Write up!** Explain your reasoning for selecting features and performing those specific feature engineering steps respectively.\n",
    "\n",
    "**Do this!** In the cells below, **explain** and perform the steps that you need to prepare this data for further analysis. Make sure that your implementations and write-ups (for processing and analysis) are presented well and effectively describe your workflow. You may add comments or markdown cells for your documentation as you see fit!  \n",
    "\n",
    "*Grading Note: Your work will be graded for _readability_, _style_, and _cleanlines_. So, carefully document your code and use descriptive/intuitive variable names. For write-ups use consice and clear language like in a written project report.*\n",
    "\n",
    "> **Hint**: You can use our previous labs as examples of how you might do this. \n",
    "Also, you might want to come back to this step later on, since you might encounter problems with the data once you actually analyze it. Remember, you may add as many cells (for code and text) as you need below. Here â€” we gave you one for free!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016bb929",
   "metadata": {},
   "source": [
    "To initially preprocess the data, we needed to drop the na values by imputing the na values with the mean of each column. As seen below, all 207 null values are in the total_bedrooms column, so we find the mean of the total_bedrooms column and then fill the null values with this mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value= np.mean(data['total_bedrooms'])\n",
    "data['total_bedrooms'].fillna(value=mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a2873",
   "metadata": {},
   "source": [
    "In the cell below, we set the X as all the columns besides median house value, and we set y, the target, as median_house_value. Then we train test split the data into an 80-20 ratio of training vs testing data. We also additionally convert the categorical column ocean_proximity to numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(\"<1H OCEAN\", 1).replace(\"INLAND\", 2).replace(\"NEAR OCEAN\", 3).replace(\"NEAR BAY\", 4).replace(\"ISLAND\", 5)\n",
    "data['ocean_proximity'] = data['ocean_proximity']*1.0\n",
    "\n",
    "X = data.loc[:, data.columns != 'median_house_value']\n",
    "y = data['median_house_value']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ebc7cd",
   "metadata": {},
   "source": [
    "\n",
    "### Problem 2.2: Perform Basic Feature Manupilation & Data Transformation\n",
    "\n",
    "1. Be consistent with the feature engineering process in train and test data. No data snooping.\n",
    "2. Handle Missing data: Fill the missing values with the mean of the respective column.\n",
    "3. Encode categorical data: Convert categorical column in the dataset to numerical data.\n",
    "4. Standardize data: Standardize training and test datasets.\n",
    "\n",
    "### Problem 2.3: Perform Feature Engineering (Feature Selection or/and Feature Generation) including but not limited to statistical, ML based, Newly extracted/created features etc. wherever appropriate/applicable in the respective Predictive Modeling part.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee8023",
   "metadata": {},
   "source": [
    "In the cell below, we scale the training and testing data using the function preprocessing.scale which standardizes/normalizes the data. It's important we do this after the train test split because this prevents data snooping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "722e3263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_test = preprocessing.scale(X_test)\n",
    "y_train = preprocessing.scale(y_train)\n",
    "y_test = preprocessing.scale(y_test)\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f0b2d4",
   "metadata": {},
   "source": [
    "## 3. Predictive Modeling [Using scikit learn pipeline is highly encouraged]\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "1. Build a model of housing prices to predict median house values in California using the provided dataset.\n",
    "2. Train the model to learn from the data to predict the median housing price in any district, given all the other metrics.\n",
    "3. Predict housing prices based on median_income and plot the regression chart for it.\n",
    "\n",
    "### Problem 3.1 : Perform K-Nearest Neighbors Regression\n",
    "\n",
    "Perform K-Nearest Neighbors Algorithm for Regression on the training data.\n",
    "\n",
    "Predict output for the test dataset using the fitted model.\n",
    "\n",
    "Print root mean squared error (RMSE) and R^2 from K-Nearest Neighbors Regression on the test datset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af55c14",
   "metadata": {},
   "source": [
    "**Write-up!** How K-NN is different than Linear regression model and what additional steps you have to take for KNN Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110bd1c9",
   "metadata": {},
   "source": [
    "**Answer here:** <br>\n",
    "K-NN is a classification model and Linear regression is a a regressional model. K-NN assumes that similar things exist in close proximity to each other. Therefore, K-NN computes distances of different data points to a certain amount of neighbors or clusters. Then, it takes the minimum distance and classifies that data point as part of that cluster, thus making it a classification problem. On the other hand, the Linear regressional model computes the least squares to fit a best line to model, then calculates the accuracy by calculating the distance from each data point to the best fit line.\n",
    "The difference between KNN regression and K-NN classification. is that KNN regression attempts to predict the value of the target by using the average whereas KNN classification attempts to predict the class/cluster that the target belongs to by maximizing the probability likelihood function.\n",
    "Therefore, an additional step for KNN regression is computing the local average of the data points to create a prediction model for the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "8590473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "57dca90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "num_cols = ['latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'median_income', \n",
    "            'median_house_value','ocean_proximity']\n",
    "\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),\n",
    "    ('robust scaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "718deafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "pipeline_kNN = Pipeline(steps=[('preprocessor', num_transformer),\n",
    "                      ('regressor', KNeighborsRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f29473ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared: 0.7107447419512194\n",
      "rmse: 0.5376849113155902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "r2_kNN = cross_val_score(pipeline_kNN, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "print(\"r-squared:\", r2_kNN)\n",
    "\n",
    "rmse_kNN = -1*cross_val_score(pipeline_kNN, X_train, y_train, cv=5, scoring ='neg_root_mean_squared_error').mean()\n",
    "print(\"rmse:\", rmse_kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2267c2",
   "metadata": {},
   "source": [
    "### Problem 3.2 : Perform Decision Tree Regression \n",
    "Perform Decision Tree Regression on the training data.\n",
    "\n",
    "Predict the output for test dataset using the fitted model.\n",
    "\n",
    "Print root mean squared error (RMSE) and R^2 from Decision Tree Regression on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557a0dd5",
   "metadata": {},
   "source": [
    "**Write-up!** What are the advantages or disadvantages of using Decision Tree over Linear regression and KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18fff26",
   "metadata": {},
   "source": [
    "**Answer here:** <br>\n",
    "Decision tree is a type of supervised machine learning that splits data based on previous sets of questions to divide the data into regressions or clusters.\n",
    "The advantages of using decision trees are there's less data preparation, non-linearity, and greater interpretability of the data given that the splits can be any arbitrary quantity. The disadvantages of using decision trees are overfitting, there's no feature reduction, and not necessarily linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5b12feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "pipeline_DT = Pipeline(steps=[('preprocessor', num_transformer),\n",
    "                      ('regressor', DecisionTreeRegressor())])\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b12094d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared: 0.6410274872607599\n",
      "rmse: 0.5971669359679141\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "r2_dt = cross_val_score(pipeline_DT, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "print(\"r-squared:\", r2_dt)\n",
    "\n",
    "rmse_dt = -1*cross_val_score(pipeline_DT, X_train, y_train, cv=5, scoring ='neg_root_mean_squared_error').mean()\n",
    "print(\"rmse:\", rmse_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ca57b",
   "metadata": {},
   "source": [
    "### Problem 3.3 : Perform Random Forest Regression :\n",
    "Perform Random Forest Regression on the training data.\n",
    "\n",
    "Predict the output for test dataset using the fitted model.\n",
    "\n",
    "Print root mean squared error (RMSE) and R^2 from Random Forest Regression on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f27d09",
   "metadata": {},
   "source": [
    "**Write-up!** How Random Forest ensures better results from Decision Tree and Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ab7211",
   "metadata": {},
   "source": [
    "**Answer here:** <br>\n",
    "Random Forest ensures better results than Decision tree because random forest repetitively selects a subset of features and makes a unique decision tree from that subset of features. In the end, it averages the results observed from the whole set of decision trees it created, therefore giving it better results from Decision Tree because it contains some sort of feature reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "00004427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipeline_RF = Pipeline(steps=[('preprocessor', num_transformer),\n",
    "                      ('regressor', RandomForestRegressor(random_state=5))])\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "aa3730a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared: 0.6411463284214433\n",
      "rmse: 0.600001354686835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "r2_rf = cross_val_score(pipeline_DT, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "print(\"r-squared:\", r2_rf)\n",
    "\n",
    "rmse_rf = -1*cross_val_score(pipeline_DT, X_train, y_train, cv=5, scoring ='neg_root_mean_squared_error').mean()\n",
    "print(\"rmse:\", rmse_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115e342a",
   "metadata": {},
   "source": [
    "### Problem 3.4: Perform Linear Regression with one independent variable\n",
    "\n",
    "Extract just the median_income column from the independent variables (from X_train and X_test).\n",
    "\n",
    "Perform Linear Regression to predict housing values based on median_income.\n",
    "\n",
    "Predict output for test dataset using the fitted model.\n",
    "\n",
    "Plot the fitted model for training data as well as for test data to check if the fitted model satisfies the test data.\n",
    "\n",
    "Compare the results of the baseline model with this model's result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbcde91",
   "metadata": {},
   "source": [
    "**Write-up!** Why there is a difference in performance (if any!) of problem 1.5 and problem 3.4 model? What kind of feature selection is being applied here and what is the intuition behind it. Describe in your words! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d406c8cf",
   "metadata": {},
   "source": [
    "**Answer here:** <br>\n",
    "There's a difference in performance because we used a pipeline for this one instead of hand computing it. Therefore, the pipeline does different computations based on statistical and probabilistic algorithms. The kind of feature selection being applied here is used to select the feature's importance from a model so it can be used to train another model. Therefore, since we weigh the feature's performance/importance, the r2 and rmse values are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "893cbc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipeline_LR = Pipeline(steps=[('preprocessor', num_transformer),\n",
    "                      ('regressor', LinearRegression())])\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b8562cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared: 0.6316258235284089\n",
      "rmse: 0.606743301657892\n"
     ]
    }
   ],
   "source": [
    "r2_lr = cross_val_score(pipeline_LR, X_train, y_train, cv=5, scoring='r2').mean()\n",
    "print(\"r-squared:\", r2_lr)\n",
    "\n",
    "rmse_lr = -1*cross_val_score(pipeline_LR, X_train, y_train, cv=5, scoring ='neg_root_mean_squared_error').mean()\n",
    "print(\"rmse:\", rmse_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a8f1bb",
   "metadata": {},
   "source": [
    "## 4. Model Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fec082",
   "metadata": {},
   "source": [
    "### Problem 4.1:\n",
    "\n",
    "Compare all the models results and report the lowest accuracy score.\n",
    "\n",
    "Visualize all the final models error using R^2 in a bar graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6c4a9ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy Scores for Final Models')"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BEGIN SOLUTION\n",
    "    \n",
    "labels = ['KNN', 'Decision Tree', 'Random Forest', 'Linear Regression']\n",
    "scores = [r2_kNN, r2_dt, r2_rf, r2_lr]\n",
    "\n",
    "# your code here \n",
    "plt.bar(labels,scores)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"R-squared\")\n",
    "plt.title(\"Accuracy Scores for Final Models\")\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562f1363",
   "metadata": {},
   "source": [
    "As seen above, the linear regression model has the lowest accuracy score compared to the other models. Its r-squared value is 0.632."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "2a368d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'RMSE Scores for Final Models')"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['KNN', 'Decision Tree', 'Random Forest', 'Linear Regression']\n",
    "scores = [rmse_kNN, rmse_dt, rmse_rf, rmse_lr]\n",
    "\n",
    "# your code here \n",
    "plt.bar(labels,scores)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"RMSE Scores for Final Models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80d7d30",
   "metadata": {},
   "source": [
    "As seen above, the k nearest neighbors has the lowest rmse score compared to the other models. Its r-squared value is 0.632. It has a RMSE value of 0.537."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87084a5e",
   "metadata": {},
   "source": [
    "### Problem 4.2:\n",
    "\n",
    "Now review the feature enginnering lab (lab 9) and apply one of the feature selection and/or one feature generation method and use it for prediction on the test data. Evaluate and compare the all the models (LR, DT, RF, K-NN) on original features (no feature engineering) with the ones on the engineered features.\n",
    "Then, select the best model after the whole comparision.\n",
    "\n",
    "Visualize the following models with and without feature engineering comparision.\n",
    "1.  Linear Regression Model (LR-all (Problem 1.5) vs LR-1feature (Problem 3.4).\n",
    "2.  KNN (No feature engineering KNN vs Feature engineered KNN)\n",
    "3.  DT (No feature engineering DT vs Feature engineered DT)\n",
    "4.  RF (No feature engineering RF vs Feature engineered RF)\n",
    "\n",
    "Visualize all models with feature enginnering in one graph and compare their R^2.\n",
    "\n",
    "**Write up** Explain which feature selection and/or feature generation method have you selected and why for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dc7125",
   "metadata": {},
   "source": [
    "**Answer here:** <br>\n",
    "For this data set I chose to do random forest because it has the highest r-squared value with feature engineering, so it would be the most interesting to see how the feature engineered random forest compares to the no feature engineering random forest in terms of accuracy in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "5c2b9582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "data_FE = data.drop(['longitude', 'latitude'], axis =1)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "443b47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_FE, X_test_FE, y_train_FE, y_test_FE = train_test_split(X, y, test_size=0.2, random_state=5)\n",
    "X_train_FE = preprocessing.scale(X_train_FE)\n",
    "X_test_FE = preprocessing.scale(X_test_FE)\n",
    "y_train_FE = preprocessing.scale(y_train_FE)\n",
    "y_test_FE = preprocessing.scale(y_test_FE)\n",
    "\n",
    "num_cols = ['housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'median_income', \n",
    "            'median_house_value','ocean_proximity']\n",
    "\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),\n",
    "    ('robust scaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ae4206a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared: 0.7107447419512194\n",
      "rmse: 0.5376849113155902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "pipeline_kNN_FE = Pipeline(steps=[('preprocessor', num_transformer),\n",
    "                      ('regressor', KNeighborsRegressor())])\n",
    "r2_kNN_FE = cross_val_score(pipeline_kNN, X_train_FE, y_train_FE, cv=5, scoring='r2').mean()\n",
    "print(\"r-squared:\", r2_kNN_FE)\n",
    "\n",
    "rmse_kNN_FE = -1*cross_val_score(pipeline_kNN_FE, X_train_FE, y_train_FE, cv=5, scoring ='neg_root_mean_squared_error').mean()\n",
    "print(\"rmse:\", rmse_kNN_FE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8c1e113e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared: 0.6400660411566245\n",
      "rmse: 0.6021365086895927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "pipeline_DT_FE = Pipeline(steps=[('preprocessor', num_transformer),\n",
    "                      ('regressor', DecisionTreeRegressor())])\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "r2_dt_FE = cross_val_score(pipeline_DT_FE, X_train_FE, y_train_FE, cv=5, scoring='r2').mean()\n",
    "print(\"r-squared:\", r2_dt_FE)\n",
    "\n",
    "rmse_dt_FE = -1*cross_val_score(pipeline_DT_FE, X_train_FE, y_train_FE, cv=5, scoring ='neg_root_mean_squared_error').mean()\n",
    "print(\"rmse:\", rmse_dt_FE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f83eba63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared: 0.6422407201357461\n",
      "rmse: 0.603917747754286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipeline_RF_FE = Pipeline(steps=[('preprocessor', num_transformer),\n",
    "                      ('regressor', RandomForestRegressor(random_state=5))])\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "r2_rf_FE = cross_val_score(pipeline_DT_FE, X_train_FE, y_train_FE, cv=5, scoring='r2').mean()\n",
    "print(\"r-squared:\", r2_rf_FE)\n",
    "\n",
    "rmse_rf_FE = -1*cross_val_score(pipeline_DT_FE, X_train_FE, y_train_FE, cv=5, scoring ='neg_root_mean_squared_error').mean()\n",
    "print(\"rmse:\", rmse_rf_FE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "97f90929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared: 0.6316258235284089\n",
      "rmse: 0.606743301657892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipeline_LR_FE = Pipeline(steps=[('preprocessor', num_transformer),\n",
    "                      ('regressor', LinearRegression())])\n",
    "r2_lr_FE = cross_val_score(pipeline_LR, X_train_FE, y_train_FE, cv=5, scoring='r2').mean()\n",
    "print(\"r-squared:\", r2_lr_FE)\n",
    "\n",
    "rmse_lr_FE = -1*cross_val_score(pipeline_LR_FE, X_train_FE, y_train_FE, cv=5, scoring ='neg_root_mean_squared_error').mean()\n",
    "print(\"rmse:\", rmse_lr_FE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "20d3dca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model     No FE        FE\n",
      "0                KNN  0.710745  0.710745\n",
      "1      Decision Tree  0.641027  0.640066\n",
      "2      Random Forest  0.641146  0.642241\n",
      "3  Linear Regression  0.631626  0.631626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature Engineering vs No Feature Engineering'}, xlabel='Model'>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['KNN', 'Decision Tree', 'Random Forest', 'Linear Regression']\n",
    "scores = [r2_kNN, r2_dt, r2_rf, r2_lr]\n",
    "scores_FE = [r2_kNN_FE, r2_dt_FE, r2_rf_FE, r2_lr_FE]\n",
    "\n",
    "df = pd.DataFrame([['KNN', r2_kNN, r2_kNN_FE], ['Decision Tree', r2_dt, r2_dt_FE], ['Random Forest', r2_rf, r2_rf_FE],\n",
    "                   ['Linear Regression', r2_lr, r2_lr_FE]],\n",
    "                  columns=['Model', 'No FE', 'FE'])\n",
    "print(df)\n",
    "  \n",
    "# plot grouped bar chart\n",
    "df.plot(x='Model',\n",
    "        kind='bar',\n",
    "        stacked=False,\n",
    "        title='Feature Engineering vs No Feature Engineering')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc38fb3",
   "metadata": {},
   "source": [
    "\n",
    "**Write up** Summarize your results and provide some crucial insights about the entire with and without feature engineering process such as which model performed the best and why, based on what metrics and indicators, etc. Which feature engireeing step provided more value to the predictive modeling process?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da13b9db",
   "metadata": {},
   "source": [
    "**Answer here:** <br>\n",
    "As seen above, our feature engineering is marginally better than the no feature engineering data set because we extracted non important features like longitude and latitude since they're not relevant to house prices. The feature engineering for k neighbors has the highest r2 value, so we should use this model for the data set in predicting house prices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "270bd35f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>hw9</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "hw9 results: All test cases passed!"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"hw9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b06ae2",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Note that we have a dummy test here to generate a pdf on Gradescope, but the entire assignment is manually graded. So make sure your notebook communicates your thoughts and process!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b7b1d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18547f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f259a52b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7b96fb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe9df1",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "otter": {
   "tests": {
    "hw9": {
     "name": "hw9",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> True == True\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
